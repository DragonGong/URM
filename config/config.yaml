env_config:
  env_id: "highway-fast-v0"
  lanes_count: 4
  vehicles_count: 50
  duration: 400
  simulation_frequency: 15
  policy_frequency: 1
  initial_spacing: 2

  observation:
    type: "Kinematics"

  other_vehicles_type: "highway_env.vehicle.behavior.IDMVehicle"
  vehicles_density: 1.0

  action:
    type: "DiscreteMetaAction"

  collision_reward: -1
  reward_speed_range: [ 20, 30 ]
  centering_position: [ 0.3, 0.5 ]

  screen_width: 600
  screen_height: 150
  scaling: 5.5
  show_trajectories: false
  render_agent: true
  offscreen_rendering: false

model_config:
  algorithm: "DQN"
  policy: "MlpPolicy"
  policy_kwargs:
    net_arch: [ 256, 256 ]
  learning_rate: 0.0005
  buffer_size: 15000
  learning_starts: 200
  batch_size: 32
  gamma: 0.8
  train_freq: 1
  gradient_steps: 1
  target_update_interval: 50
  verbose: 1
  tensorboard_log: "highway_dqn/"

reward:
  step_num: 3
  duration: 1
  desired_speed: 20
  r_safe_w: 0.7
  r_speed_w: 0.2
  r_lateral_w: 0.1
  v2r_w: 0.1
  baseline_reward_w: 0.5

  discount_factor_max: 0.8
  discount_factor_min: 0.2
  velocity_unit: 20
  risk_max_for_tree: 1

  prediction_model: "linear_model"
  prediction_model_configs:
    linear_model_config: {}

  fitting_model: "polynomial"
  fitting_model_config:
    polynomial: {}

  behavior_configs:
    behaviors_list: [ "lateral_left","lateral_right","soft_accel","hard_accel","soft_decel","hard_decel" ]

  riskmap_config:
    cell_size: 0.5

training:
  total_timesteps: 10000
  save_dir: "./agent"

test_config:
  model_path: "./agent/default_model"
  render_mode: "human" # 可选: "human", "rgb_array", null
  test_episodes: 1
# urm riskmap baseline
env_wrapper: "riskmap"
